{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca655c3-b71f-4ef9-aeb0-9d79cb7210e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85d9b41-a03e-48bb-b4fc-0a1323b86c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --quiet --upgrade deepface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a06a57c-9b94-44d7-a0df-def4bae821af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from sklearn.decomposition import PCA\n",
    "from deepface import DeepFace\n",
    "from sklearn.manifold import TSNE\n",
    "from UDCUtils import UDCUtils\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import contextlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407798bc-07a2-4084-b283-898d63a918ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils = UDCUtils()\n",
    "\n",
    "pinecone_api_key = utils.get_pinecone_api_key()\n",
    "\n",
    "pinecone_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e126604-6ad0-449a-8747-8692a9d0699c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget -q --show-progress -O \"images/family_photos.zip\" \"https://www.dropbox.com/scl/fi/yg0f2ynbzzd2q4nsweti5/family_photos.zip?rlkey=00oeuiii3jgapz2b1bfj0vzys&dl=0\"\n",
    "\n",
    "#!unzip -q images/family_photos.zip images/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87549225-d0b1-45cb-b3ed-aacece68a80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(img):\n",
    "    l_img = plt.imread(img)\n",
    "    plt.figure(figsize=[4,4])\n",
    "    plt.imshow(l_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188431d6-ddcf-418a-be9a-e4f9459ef605",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img(\"images/family/mom/P04407_face2.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d218845a-27b7-420f-8c50-b69cb89f6eda",
   "metadata": {},
   "source": [
    "## Setup pinecone object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b79c31-f9f3-4aa1-a43e-bc34f8b66b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone = Pinecone(api_key=pinecone_api_key)\n",
    "\n",
    "index_name = utils.create_dlai_index_name(\"idx-img-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e297dda4-94ee-4090-a729-aefb289e2b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.create_index(\n",
    "    name=index_name,\n",
    "    spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "    metric=\"cosine\",\n",
    "    dimension=128\n",
    ")\n",
    "\n",
    "INDEX = pinecone.Index(index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ff61a4-684c-4cc3-9ca4-d1b4fb98c4df",
   "metadata": {},
   "source": [
    "## Create Embeddings using DeepFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19953fea-e322-4865-8ff0-f151168eeb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "MODEL=\"Facenet\"\n",
    "def generate_vectors(folder_list:list):\n",
    "    VECTOR_FILE = \"vectors/FACIAL_SEARCH_MONARCHS.vec\"\n",
    "\n",
    "    with contextlib.suppress(FileNotFoundError):\n",
    "        os.remove(VECTOR_FILE)\n",
    "\n",
    "    with open(VECTOR_FILE,\"x\") as f:\n",
    "        for person in folder_list:\n",
    "            files = glob.glob(f'images/family/{person}/*')\n",
    "            for file in tqdm(files):\n",
    "                try:\n",
    "                    embedding = DeepFace.represent(img_path=file, model_name=MODEL, enforce_detection=False)[0]['embedding']\n",
    "                    f.write(f'{person}:{os.path.basename(file)}:{embedding}\\n')\n",
    "                except (ValueError, UnboundLocalError, AttributeError) as e:\n",
    "                    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4301cd-4504-40b5-b2d8-f0915875ee77",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_vectors(['dad','mom','child'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb76bc7-2609-4191-b80d-0da6c4a18d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -5 \"vectors/FACIAL_SEARCH_MONARCHS.vec\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f48a5bd-3d4f-4771-b7f3-199944299942",
   "metadata": {},
   "source": [
    "## Plot images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67eab76-25e8-4b4f-a50c-2a794bc9fe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_tsne_dataframe(person, perplexity, vector_file):\n",
    "    vectors=[]\n",
    "    with open(vector_file,\"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            p, orig_img, emb = line.split(\":\")\n",
    "            if p==person:\n",
    "                vectors.append(eval(emb))\n",
    "\n",
    "    pca = PCA(n_components=8)\n",
    "    tsne = TSNE(2, perplexity=perplexity, random_state=0, n_iter=1000, verbose=0, metric=\"euclidean\", learning_rate=75)\n",
    "    print(f\"Transforming {len(vectors)} vectors\")\n",
    "    pca_transform_vectors = pca.fit_transform(vectors)\n",
    "    embeddings2d = tsne.fit_transform(pca_transform_vectors)\n",
    "\n",
    "    return pd.DataFrame({'x':embeddings2d[:,0],'y':embeddings2d[:,1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e024dea-bcd6-4c5c-9002-f5cce8bf8c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tsne(perplexity, model, persons, vector_file):\n",
    "    (_, ax) = plt.subplots(figsize=(8,5))\n",
    "    #plt.style.use('seaborn-whitegrid')\n",
    "    plt.grid(color='#EAEAEB', linewidth=0.5)\n",
    "    ax.spines['top'].set_color(None)\n",
    "    ax.spines['right'].set_color(None)\n",
    "    ax.spines['left'].set_color('#2B2F30')\n",
    "    ax.spines['bottom'].set_color('#2B2F30')\n",
    "    colormap = {f'{persons[0]}':'#ee8933', f'{persons[1]}':'#4fad5b', f'{persons[2]}':'#4c93db'}\n",
    "\n",
    "    for person in colormap:\n",
    "        embeddingsdf = gen_tsne_dataframe(person, perplexity, vector_file)\n",
    "        ax.scatter(embeddingsdf.x, embeddingsdf.y, alpha=.5, \n",
    "                   label=person, color=colormap[person])\n",
    "    plt.title(f'Scatter plot of faces using {model}', fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.suptitle(f't-SNE [perplexity={perplexity}]', y=0.92, fontsize=13)\n",
    "    plt.legend(loc='best', frameon=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7156fb-b2b7-4210-84fa-914a5a5beeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tsne(44, 'facenet', persons=['dad','child','mom'], vector_file=\"vectors/FACIAL_SEARCH_MONARCHS.vec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39855aa-8969-4e50-8082-0d754b3fd83f",
   "metadata": {},
   "source": [
    "## Upsert vectors to pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3600bd4-e1b7-471f-8f5b-0a81435c1aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX.delete(delete_all=True, namespace='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d76f78b-175d-4273-8396-2fb4a02cf3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_file=\"vectors/FACIAL_SEARCH_MONARCHS.vec\"\n",
    "prepped=[]\n",
    "cnt=0\n",
    "with open(vector_file, \"r\") as f:\n",
    "    for line in tqdm(f):\n",
    "        cnt = cnt + 1\n",
    "        person, imgfile, embeddings = line.split(\":\")\n",
    "        prepped.append(\n",
    "            {'id':f'{person}-{cnt}',\n",
    "            'values':eval(embeddings),\n",
    "            'metadata':{'person':person, 'file':imgfile}}\n",
    "        )\n",
    "        INDEX.upsert(prepped)\n",
    "        #INDEX.upsert([(f'{person}-{imgfile}', eval(embeddings), {'person':person, 'file':imgfile})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b51317-a5b5-40ef-a69d-c56598b60573",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepped.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8b0890-c21e-47a8-821e-9ffd6fdbba8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e35872-b497-4d60-afc9-1157504a28a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f35924b-704b-4907-9f48-f6bd5a7ae552",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = INDEX.fetch(ids=['dad-1'])\n",
    "print(val.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b86377-9cef-4d14-9d3f-946c455c6211",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test which of the parent resembles most to the child \n",
    "def compute_match_scores(vec_groups, parent, child):\n",
    "    index = pinecone.Index(index_name)\n",
    "    parent_vecs = vec_groups[parent]\n",
    "    print(len(parent_vecs))\n",
    "    K=10\n",
    "    SAMPLE_SIZE=10\n",
    "    sum=0\n",
    "\n",
    "    for i in tqdm(range(0, SAMPLE_SIZE)):\n",
    "        print(type(parent_vecs[i]))\n",
    "        print(f'{child}{type(child)}')\n",
    "        response = index.query(\n",
    "            vector=parent_vecs[i],\n",
    "            filter={\n",
    "                \"person\":{\"$eq\": child}\n",
    "            },\n",
    "            top_k=K,\n",
    "            include_metadata=True\n",
    "        )\n",
    "    for r in response[\"matches\"]:\n",
    "        sum = sum + r[\"score\"]\n",
    "    print(f\"Average match score for {parent} is {sum/(SAMPLE_SIZE*K)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899decba-9d81-47cc-97be-487336807cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    vector_grps = {\"dad\":[], \"mom\":[], \"child\":[]}\n",
    "    with open(vector_file, \"r\") as f:\n",
    "        for line in tqdm(f):\n",
    "            person, imgfile, emb = line.split(\":\")\n",
    "            vector_grps[person].append(eval(emb))\n",
    "\n",
    "    print(f\"DAD \\n{'-' * 20}\")\n",
    "    compute_match_scores(vector_grps, \"dad\", \"child\")\n",
    "    print(f\"MOM \\n{'-' * 20}\")\n",
    "    compute_match_scores(vector_grps, \"mom\", \"child\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51fd4cd-83e4-47d0-9770-c9fc57d58d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daacde8f-271c-414b-96b5-01e165309fd0",
   "metadata": {},
   "source": [
    "## Checking the matching images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293c3f3f-8fbe-4108-9403-04f426266dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "child_base = 'images/family/child/P06310_face1.jpg'\n",
    "show_img(child_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c633195a-3b8c-4cf7-875e-abceafb3168d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding closest image of dad (given the score for dad is greater than mom)\n",
    "embedding = DeepFace.represent(img_path=child_base, model_name=MODEL)[0]['embedding']\n",
    "#print(embedding)\n",
    "\n",
    "response = INDEX.query(\n",
    "    vector=embedding,\n",
    "    filter={\n",
    "        'person':{\"$eq\":\"dad\"}\n",
    "    },\n",
    "    top_k=10,\n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "print(response[\"matches\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e797c91-4d16-4250-afcd-aeff54b3a081",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img(\"images/family/dad/\"+response[\"matches\"][0][\"metadata\"][\"file\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfdf186-b826-494d-82f3-c694eb0ba5a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6f513b-5496-4876-aa4e-f148d5ba55f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94ba97b7-c8e7-4ed7-bebd-bd2202ecd87c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
