{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8987732-bc50-4731-9320-729219559bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82849dbe-1865-4f86-a23d-2aa0d8e0395f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f77f7a-1165-4aac-b6dc-dff3a584d24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pinecone_text.sparse import BM25Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c381399-840a-45be-91da-2aebceb18ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1eaa50-3993-45e2-9d8d-3f52c87a2adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from UDCUtils import UDCUtils\n",
    "utils = UDCUtils()\n",
    "\n",
    "pinecone_api_key = utils.get_pinecone_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd99a44a-b930-458a-9097-448e6df261a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdc26b0-3104-4aa5-90df-a469cda909d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone = Pinecone(api_key=pinecone_api_key)\n",
    "help(pinecone.delete_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d438b481-9975-4677-aa0d-69b7fbc76a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = utils.create_dlai_index_name(\"dev-002\")\n",
    "#print(index_name)\n",
    "index_name = index_name[:-3]\n",
    "#print(index_name)\n",
    "if index_name in [index['name'] for index in pinecone.list_indexes()]:\n",
    "    print(f\"{index_name} is an existing index. Kindly delete it.\")\n",
    "    pinecone.delete_index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9461a8f3-bb31-4891-9444-5d26e840d827",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "if device!='cuda':\n",
    "    print(\"Sorry, cuda is not available. Proceeding ahead with CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04143f1f-7f08-43ba-901c-182de6fb63f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.create_index(\n",
    "    name=index_name,\n",
    "    metric='dotproduct',\n",
    "    dimension=512,\n",
    "    spec=ServerlessSpec(cloud='aws', region='us-east-1')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c582ebf4-5db1-481e-8341-16a490a17746",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pinecone.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6040c709-3512-43c7-a588-50b0fd50f7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(load_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8811a12-004a-4495-8d78-8ee2945266fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install ipywidgets==7.7.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228be3f1-52bb-451a-97a7-7d005096d415",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion = load_dataset(\n",
    "    \"ashraq/fashion-product-images-small\",\n",
    "    split=\"train\"\n",
    ")\n",
    "fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c5f2e6-2a9a-4050-b38b-6cc289397604",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = fashion['image']\n",
    "images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9548a20-e880-4476-bb69-7d86ad5963b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = fashion.remove_columns('image')\n",
    "metadata[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5083fc6e-9dff-46ad-8075-274e4eb6c567",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = metadata.to_pandas()\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cec437-8358-4c18-86c3-5311aadd1879",
   "metadata": {},
   "source": [
    "### Create sparse vector using BM25Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6d2676-6edf-4e87-a7f1-68d7c67dac0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25encoder = BM25Encoder()\n",
    "bm25encoder.fit(metadata['productDisplayName'])\n",
    "metadata['productDisplayName'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9ce4c0-07ce-4eae-a3cf-86d05aa859e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25encoder.encode_queries(metadata['productDisplayName'][0])\n",
    "bm25encoder.encode_documents(metadata['productDisplayName'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75cff7a-7e6c-47d7-a7d4-c8b9b2956196",
   "metadata": {},
   "source": [
    "### Create dense vector using CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565a1ea8-8cdb-4f75-878c-60c927ce9e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ipywidgets==7.7.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb27c87d-de62-48f5-ab8c-484ea25dd1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\n",
    "    'sentence-transformers/clip-ViT-B-32',\n",
    "    device=device\n",
    ")\n",
    "\n",
    "#check the dim\n",
    "clip_vector = model.encode(metadata['productDisplayName'][0])\n",
    "clip_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319d9a44-2c29-48f8-856f-56f9fc5bc99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fashion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13db6861-e3d5-47f2-934d-ad8bd1aa3db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "fashion_data_num = 1000\n",
    "\n",
    "for i in tqdm(range(0, min(fashion_data_num,len(fashion)), batch_size)):\n",
    "    # find end of batch\n",
    "    i_end = min(i+batch_size, len(fashion))\n",
    "    \n",
    "    # extract metadata batch\n",
    "    meta_batch = metadata.iloc[i:i_end]\n",
    "    meta_dict = meta_batch.to_dict(orient=\"records\")\n",
    "    \n",
    "    # concatinate all metadata field except for id and year to form a single string\n",
    "    meta_batch = [\" \".join(x) for x in meta_batch.loc[:, ~meta_batch.columns.isin(['id', 'year'])].values.tolist()]\n",
    "    \n",
    "    # extract image batch\n",
    "    img_batch = images[i:i_end]\n",
    "    \n",
    "    # create sparse using bm25encoder for metadata\n",
    "    sparse_embeds = bm25encoder.encode_documents([text for text in meta_batch])\n",
    "    \n",
    "    # create dense vectors using clip model for images\n",
    "    dense_embeds = model.encode(img_batch).tolist()\n",
    "    \n",
    "    # create unique IDs\n",
    "    ids = [str(x) for x in range(i, i_end)]\n",
    "\n",
    "    upserts = []\n",
    "    # loop through the data and create dictionaries for uploading documents to pinecone index\n",
    "    for _id, sparse, dense, meta in zip(ids, sparse_embeds, dense_embeds, meta_dict):\n",
    "        upserts.append({\n",
    "            'id': _id,\n",
    "            'sparse_values': sparse,\n",
    "            'values': dense,\n",
    "            'metadata': meta\n",
    "        })\n",
    "    # upload the documents to the new hybrid index\n",
    "    index.upsert(upserts)\n",
    "\n",
    "# show index description after uploading the documents\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804ef168-2a92-483d-9d60-8ff168af2ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"navy blue shirt for women\"\n",
    "\n",
    "sparse_vec = bm25encoder.encode_queries(query)\n",
    "dense_vec = model.encode(query).tolist()\n",
    "\n",
    "result = index.query(\n",
    "    top_k=10,\n",
    "    vector=dense_vec,\n",
    "    sparse_vector=sparse_vec,\n",
    "    include_metadata=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95771fe7-342e-4ef3-8c12-c041d5972752",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "for r in result[\"matches\"]:\n",
    "    #print(r)\n",
    "    imgs.append(images[int(r[\"id\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3385df1b-e41b-40ed-ae85-021f1e91236f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "from io import BytesIO\n",
    "from base64 import b64encode\n",
    "\n",
    "# function to display product images\n",
    "def display_result(image_batch):\n",
    "    figures = []\n",
    "    for img in image_batch:\n",
    "        b = BytesIO()\n",
    "        img.save(b, format='png')\n",
    "        figures.append(f'''\n",
    "            <figure style=\"margin: 5px !important;\">\n",
    "              <img src=\"data:image/png;base64,{b64encode(b.getvalue()).decode('utf-8')}\" style=\"width: 90px; height: 120px\" >\n",
    "            </figure>\n",
    "        ''')\n",
    "    return HTML(data=f'''\n",
    "        <div style=\"display: flex; flex-flow: row wrap; text-align: center;\">\n",
    "        {''.join(figures)}\n",
    "        </div>\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff1363c-45fe-47bb-a23b-96be1f868abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_result(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648c157d-73e6-4c75-b329-57adb7651b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in result[\"matches\"]:\n",
    "    print(r[\"metadata\"][\"productDisplayName\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dedb73-c82b-4112-971f-14032478011e",
   "metadata": {},
   "source": [
    "### Scaling the hybrid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d9de8f-54f7-4b4d-a6e4-c5e811c8c06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_scale(dense, sparse, alpha: float):\n",
    "    \"\"\"Hybrid vector scaling using a convex combination\n",
    "\n",
    "    alpha * dense + (1 - alpha) * sparse\n",
    "\n",
    "    Args:\n",
    "        dense: Array of floats representing\n",
    "        sparse: a dict of `indices` and `values`\n",
    "        alpha: float between 0 and 1 where 0 == sparse only\n",
    "               and 1 == dense only\n",
    "    \"\"\"\n",
    "    if alpha < 0 or alpha > 1:\n",
    "        raise ValueError(\"Alpha must be between 0 and 1\")\n",
    "    # scale sparse and dense vectors to create hybrid search vecs\n",
    "    hsparse = {\n",
    "        'indices': sparse['indices'],\n",
    "        'values':  [v * (1 - alpha) for v in sparse['values']]\n",
    "    }\n",
    "    hdense = [v * alpha for v in dense]\n",
    "    return hdense, hsparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30830662-8cc0-4d7e-ac17-08c47119043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_query = \"navy blue shirt for women\"\n",
    "\n",
    "dense = model.encode(search_query).tolist()\n",
    "sparse = bm25encoder.encode_queries(search_query)\n",
    "\n",
    "#alpha is at extreme level, for a very dense vector\n",
    "hdense, hsparse = hybrid_scale(dense, sparse, 1)\n",
    "\n",
    "response = index.query(\n",
    "    top_k=3,\n",
    "    vector=hdense,\n",
    "    sparse_vector=hsparse,\n",
    "    include_metadata=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a7f7a5-1a69-4c02-8a11-5b87e9715a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "for res in response[\"matches\"]:\n",
    "    imgs.append(images[int(res[\"id\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eed0457-d17f-47df-8965-685cc6f57191",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab790f79-b441-4c15-a5dd-b6d5d28bcf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_result(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822c5c4b-aa6f-4bfa-b598-3b919b19c2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in response['matches']:\n",
    "    print(r[\"metadata\"][\"productDisplayName\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648e4c9b-34df-4afb-8d56-9ec8ecd2f537",
   "metadata": {},
   "source": [
    "### More sparse hybrid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8ae71d-b47d-4fa9-9f57-026ea7799b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdense, hsparse = hybrid_scale(dense, sparse, alpha=0)\n",
    "\n",
    "response = index.query(\n",
    "    top_k=3,\n",
    "    vector=dense,\n",
    "    sparse_vector=sparse,\n",
    "    include_metadata=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01e7a06-30a0-43a7-9e3d-a623989ee02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = [images[int(r[\"id\"])] for r in response[\"matches\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14728b2-e1d8-45c4-80b2-69e49b65586b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_result(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626974e1-4f49-4cf7-b623-e1d9dbc4c2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in response[\"matches\"]:\n",
    "    print(r[\"metadata\"][\"productDisplayName\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe742e02-61b0-465f-95bf-5ab801bf98ed",
   "metadata": {},
   "source": [
    "### experiment with value of alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ecab88-aeef-4735-a6b6-7b51f919a1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdense, hsparse = hybrid_scale(dense, sparse, alpha=0.5)\n",
    "\n",
    "response = index.query(\n",
    "    top_k=10,\n",
    "    vector=dense,\n",
    "    sparse_vector=sparse,\n",
    "    include_metadata=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74d8fbc-a26a-490e-8d51-aaa3ac605a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = [images[int(r[\"id\"])] for r in response[\"matches\"]]\n",
    "display_result(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db5d49c-f0ba-464a-8a33-01d8987d99e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in response[\"matches\"]:\n",
    "    print(f\"{r[\"score\"]}: {r[\"metadata\"][\"productDisplayName\"]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
